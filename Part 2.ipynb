{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_timeseries(filename, params):\n",
    "    \"\"\"Load time series dataset\"\"\"\n",
    "\n",
    "    series = pd.read_csv(r\"/Users/shama/Desktop/flipr/ts.csv\", sep=',', header=0, index_col=0, squeeze=True)\n",
    "    data = series.values\n",
    "\n",
    "    adjusted_window = params['window_size']+ 1\n",
    "\n",
    "    # Split data into windows\n",
    "    raw = []\n",
    "    for index in range(len(data) - adjusted_window):\n",
    "        raw.append(data[index: index + adjusted_window])\n",
    "\n",
    "    # Normalize data\n",
    "    result = normalize_windows(raw)\n",
    "\n",
    "    raw = np.array(raw)\n",
    "    result = np.array(result)\n",
    "\n",
    "    # Split the input dataset into train and test\n",
    "    split_ratio = round(params['train_test_split'] * result.shape[0])\n",
    "    train = result[:int(split_ratio), :]\n",
    "    np.random.shuffle(train)\n",
    "\n",
    "    # x_train and y_train, for training\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "\n",
    "    # x_test and y_test, for testing\n",
    "    x_test = result[int(split_ratio):, :-1]\n",
    "    y_test = result[int(split_ratio):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    x_test_raw = raw[int(split_ratio):, :-1]\n",
    "    y_test_raw = raw[int(split_ratio):, -1]\n",
    "\n",
    "    # Last window, for next time stamp prediction\n",
    "    last_raw = [data[-params['window_size']:]]\n",
    "    last = normalize_windows(last_raw)\n",
    "    last = np.array(last)\n",
    "    last = np.reshape(last, (last.shape[0], last.shape[1], 1))\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test, x_test_raw, y_test_raw, last_raw, last]\n",
    "\n",
    "def normalize_windows(window_data):\n",
    "    \"\"\"Normalize data\"\"\"\n",
    "\n",
    "    normalized_data = []\n",
    "    for window in window_data:\n",
    "        normalized_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        normalized_data.append(normalized_window)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "def rnn_lstm(layers, params):\n",
    "    \"\"\"Build RNN (LSTM) model on top of Keras and Tensorflow\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(input_shape=(layers[1], layers[0]), output_dim=layers[1], return_sequences=True))\n",
    "    model.add(Dropout(params['dropout_keep_prob']))\n",
    "    model.add(LSTM(layers[2], return_sequences=False))\n",
    "    model.add(Dropout(params['dropout_keep_prob']))\n",
    "    model.add(Dense(output_dim=layers[3]))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "    return model\n",
    "\n",
    "def predict_next_timestamp(model, history):\n",
    "    \"\"\"Predict the next time stamp given a sequence of history data\"\"\"\n",
    "\n",
    "    prediction = model.predict(history)\n",
    "    prediction = np.reshape(prediction, (prediction.size,))\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3f6f3ed4429a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdata_helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_helpers'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from deeppavlov import configs, build_model\n",
    "import data_helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_predict():\n",
    "    \"\"\"Train and predict time series data\"\"\"\n",
    "\n",
    "    # Load command line arguments \n",
    "    train_file = sys.argv[1]\n",
    "    parameter_file = sys.argv[2]\n",
    "\n",
    "    # Load training parameters\n",
    "    params = json.loads(open(parameter_file).read())\n",
    "\n",
    "    # Load time series dataset, and split it into train and test\n",
    "    x_train, y_train, x_test, y_test, x_test_raw, y_test_raw,\\\n",
    "        last_window_raw, last_window = data_helpers.load_timeseries(train_file, params)\n",
    "\n",
    "    # Build RNN (LSTM) model\n",
    "    lstm_layer = [1, params['window_size'], params['hidden_unit'], 1]\n",
    "    model = build_model.rnn_lstm(lstm_layer, params)\n",
    "\n",
    "    # Train RNN (LSTM) model with train set\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=params['batch_size'],\n",
    "        epochs=params['epochs'],\n",
    "        validation_split=params['validation_split'])\n",
    "\n",
    "    # Check the model against test set\n",
    "    predicted = build_model.predict_next_timestamp(model, x_test)        \n",
    "    predicted_raw = []\n",
    "    for i in range(len(x_test_raw)):\n",
    "        predicted_raw.append((predicted[i] + 1) * x_test_raw[i][0])\n",
    "\n",
    "    # Plot graph: predicted VS actual\n",
    "    plt.subplot(111)\n",
    "    plt.plot(predicted_raw, label='Actual')\n",
    "    plt.plot(y_test_raw, label='Predicted')\t\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Predict next time stamp \n",
    "    next_timestamp = build_model.predict_next_timestamp(model, last_window)\n",
    "    next_timestamp_raw = (next_timestamp[0] + 1) * last_window_raw[0][0]\n",
    "    print('The next time stamp forecasting is: {}'.format(next_timestamp_raw))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # python3 train_predict.py ./data/sales.csv ./training_config.json_\n",
    "    train_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+git://github.com/qevo/py_data_helper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipenv install --dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
